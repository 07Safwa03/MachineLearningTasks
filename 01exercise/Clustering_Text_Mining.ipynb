{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtj1QG0ps+2ju7rf344ktw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/07Safwa03/MachineLearningTasks/blob/main/01exercise/Clustering_Text_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pra Pemrosesan Teks"
      ],
      "metadata": {
        "id": "xYV2TcS7qSse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "!pip install nltk # Install NLTK\n",
        "nltk.download('stopwords') # Download the stopwords corpus\n",
        "nltk.download('punkt') # Download the punkt resource for sentence tokenization\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "text = \"Saya tidak akan lagi naik air asia..Bener bener mengecewakan ..kecewa kecewa kecewa..gitu aja yang bs saya jelaskan..malas panjang lebar inti nya nda akan naik air asia lagi\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "words = word_tokenize(text.lower())\n",
        "filtered_words = [ps.stem(w) for w in words if not w in stop_words]\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFAMBFS7p7Mn",
        "outputId": "88886469-97e1-4a08-99ea-b3b6332fc1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['saya', 'tidak', 'akan', 'lagi', 'naik', 'air', 'asia', '..', 'bener', 'bener', 'mengecewakan', '..', 'kecewa', 'kecewa', 'kecewa', '..', 'gitu', 'aja', 'yang', 'bs', 'saya', 'jelaskan', '..', 'mala', 'panjang', 'lebar', 'inti', 'nya', 'nda', 'akan', 'naik', 'air', 'asia', 'lagi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekstraksi Fitur"
      ],
      "metadata": {
        "id": "fegWS7xZqaQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "documents = [\"Text clustering organizes documents.\",\n",
        "             \"Documents are grouped based on similarity.\",\n",
        "             \"Clustering is an unsupervised learning method.\"]\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(documents)\n",
        "print(X.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOQATupUqBHu",
        "outputId": "03b6d2bc-7e08-496e-ef20-4f0ec62f6707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.42804604 0.42804604 0.         0.         0.\n",
            "  0.5628291  0.         0.5628291  0.        ]\n",
            " [0.52863461 0.         0.40204024 0.52863461 0.         0.\n",
            "  0.         0.52863461 0.         0.        ]\n",
            " [0.         0.40204024 0.         0.         0.52863461 0.52863461\n",
            "  0.         0.         0.         0.52863461]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penerapan Algoritma Clustering"
      ],
      "metadata": {
        "id": "eIvyZCOjqgIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "num_clusters = 2\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "print(kmeans.labels_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3adG39QvqCVh",
        "outputId": "e36f2a9f-db4b-46c6-ef4f-0e32dc605bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis Hasil Clustering"
      ],
      "metadata": {
        "id": "QC0nKPKtqjdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "for i in range(num_clusters):\n",
        "    print(f\"Cluster {i} top keywords:\")\n",
        "    for ind in order_centroids[i, :10]:  # Top 10 keyword\n",
        "        print(f' {terms[ind]}')\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYAG2OPpqFcN",
        "outputId": "cd05a1bc-b4c7-4a97-de20-58266b5be154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0 top keywords:\n",
            " documents\n",
            " text\n",
            " organizes\n",
            " similarity\n",
            " grouped\n",
            " based\n",
            " clustering\n",
            " unsupervised\n",
            " method\n",
            " learning\n",
            "\n",
            "Cluster 1 top keywords:\n",
            " unsupervised\n",
            " method\n",
            " learning\n",
            " clustering\n",
            " text\n",
            " similarity\n",
            " organizes\n",
            " grouped\n",
            " documents\n",
            " based\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi Clustering"
      ],
      "metadata": {
        "id": "ptvjBOxrqpka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "silhouette_avg = silhouette_score(X, kmeans.labels_)\n",
        "print(f'Silhouette Score: {silhouette_avg}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "macPnPjuqL5D",
        "outputId": "af72ac8c-497d-4748-a95f-17586f93a46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: 0.03003511786601104\n"
          ]
        }
      ]
    }
  ]
}